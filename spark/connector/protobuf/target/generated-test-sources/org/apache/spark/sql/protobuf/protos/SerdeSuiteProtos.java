// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: serde_suite.proto

package org.apache.spark.sql.protobuf.protos;

public final class SerdeSuiteProtos {
  private SerdeSuiteProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface SerdeBasicMessageOrBuilder extends
      // @@protoc_insertion_point(interface_extends:org.apache.spark.sql.protobuf.protos.SerdeBasicMessage)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
     * @return Whether the foo field is set.
     */
    boolean hasFoo();
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
     * @return The foo.
     */
    org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo getFoo();
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
     */
    org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FooOrBuilder getFooOrBuilder();
  }
  /**
   * <pre>
   * Clean Message
   * </pre>
   *
   * Protobuf type {@code org.apache.spark.sql.protobuf.protos.SerdeBasicMessage}
   */
  public static final class SerdeBasicMessage extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:org.apache.spark.sql.protobuf.protos.SerdeBasicMessage)
      SerdeBasicMessageOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SerdeBasicMessage.newBuilder() to construct.
    private SerdeBasicMessage(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SerdeBasicMessage() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SerdeBasicMessage();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_SerdeBasicMessage_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_SerdeBasicMessage_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage.Builder.class);
    }

    public static final int FOO_FIELD_NUMBER = 1;
    private org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo foo_;
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
     * @return Whether the foo field is set.
     */
    @java.lang.Override
    public boolean hasFoo() {
      return foo_ != null;
    }
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
     * @return The foo.
     */
    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo getFoo() {
      return foo_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.getDefaultInstance() : foo_;
    }
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
     */
    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FooOrBuilder getFooOrBuilder() {
      return foo_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.getDefaultInstance() : foo_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (foo_ != null) {
        output.writeMessage(1, getFoo());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (foo_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getFoo());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage other = (org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage) obj;

      if (hasFoo() != other.hasFoo()) return false;
      if (hasFoo()) {
        if (!getFoo()
            .equals(other.getFoo())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFoo()) {
        hash = (37 * hash) + FOO_FIELD_NUMBER;
        hash = (53 * hash) + getFoo().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Clean Message
     * </pre>
     *
     * Protobuf type {@code org.apache.spark.sql.protobuf.protos.SerdeBasicMessage}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:org.apache.spark.sql.protobuf.protos.SerdeBasicMessage)
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessageOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_SerdeBasicMessage_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_SerdeBasicMessage_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage.Builder.class);
      }

      // Construct using org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        foo_ = null;
        if (fooBuilder_ != null) {
          fooBuilder_.dispose();
          fooBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_SerdeBasicMessage_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage getDefaultInstanceForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage build() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage buildPartial() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage result = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.foo_ = fooBuilder_ == null
              ? foo_
              : fooBuilder_.build();
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage) {
          return mergeFrom((org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage other) {
        if (other == org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage.getDefaultInstance()) return this;
        if (other.hasFoo()) {
          mergeFoo(other.getFoo());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getFooFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo foo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FooOrBuilder> fooBuilder_;
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
       * @return Whether the foo field is set.
       */
      public boolean hasFoo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
       * @return The foo.
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo getFoo() {
        if (fooBuilder_ == null) {
          return foo_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.getDefaultInstance() : foo_;
        } else {
          return fooBuilder_.getMessage();
        }
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
       */
      public Builder setFoo(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo value) {
        if (fooBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          foo_ = value;
        } else {
          fooBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
       */
      public Builder setFoo(
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.Builder builderForValue) {
        if (fooBuilder_ == null) {
          foo_ = builderForValue.build();
        } else {
          fooBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
       */
      public Builder mergeFoo(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo value) {
        if (fooBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            foo_ != null &&
            foo_ != org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.getDefaultInstance()) {
            getFooBuilder().mergeFrom(value);
          } else {
            foo_ = value;
          }
        } else {
          fooBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
       */
      public Builder clearFoo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        foo_ = null;
        if (fooBuilder_ != null) {
          fooBuilder_.dispose();
          fooBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.Builder getFooBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getFooFieldBuilder().getBuilder();
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FooOrBuilder getFooOrBuilder() {
        if (fooBuilder_ != null) {
          return fooBuilder_.getMessageOrBuilder();
        } else {
          return foo_ == null ?
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.getDefaultInstance() : foo_;
        }
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.Foo foo = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FooOrBuilder> 
          getFooFieldBuilder() {
        if (fooBuilder_ == null) {
          fooBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FooOrBuilder>(
                  getFoo(),
                  getParentForChildren(),
                  isClean());
          foo_ = null;
        }
        return fooBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:org.apache.spark.sql.protobuf.protos.SerdeBasicMessage)
    }

    // @@protoc_insertion_point(class_scope:org.apache.spark.sql.protobuf.protos.SerdeBasicMessage)
    private static final org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage();
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SerdeBasicMessage>
        PARSER = new com.google.protobuf.AbstractParser<SerdeBasicMessage>() {
      @java.lang.Override
      public SerdeBasicMessage parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<SerdeBasicMessage> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SerdeBasicMessage> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.SerdeBasicMessage getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FooOrBuilder extends
      // @@protoc_insertion_point(interface_extends:org.apache.spark.sql.protobuf.protos.Foo)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>int32 bar = 1;</code>
     * @return The bar.
     */
    int getBar();
  }
  /**
   * Protobuf type {@code org.apache.spark.sql.protobuf.protos.Foo}
   */
  public static final class Foo extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:org.apache.spark.sql.protobuf.protos.Foo)
      FooOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Foo.newBuilder() to construct.
    private Foo(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Foo() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Foo();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_Foo_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_Foo_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.Builder.class);
    }

    public static final int BAR_FIELD_NUMBER = 1;
    private int bar_ = 0;
    /**
     * <code>int32 bar = 1;</code>
     * @return The bar.
     */
    @java.lang.Override
    public int getBar() {
      return bar_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (bar_ != 0) {
        output.writeInt32(1, bar_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (bar_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, bar_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo other = (org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo) obj;

      if (getBar()
          != other.getBar()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + BAR_FIELD_NUMBER;
      hash = (53 * hash) + getBar();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code org.apache.spark.sql.protobuf.protos.Foo}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:org.apache.spark.sql.protobuf.protos.Foo)
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FooOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_Foo_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_Foo_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.Builder.class);
      }

      // Construct using org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        bar_ = 0;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_Foo_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo getDefaultInstanceForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo build() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo buildPartial() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo result = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.bar_ = bar_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo) {
          return mergeFrom((org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo other) {
        if (other == org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo.getDefaultInstance()) return this;
        if (other.getBar() != 0) {
          setBar(other.getBar());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                bar_ = input.readInt32();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int bar_ ;
      /**
       * <code>int32 bar = 1;</code>
       * @return The bar.
       */
      @java.lang.Override
      public int getBar() {
        return bar_;
      }
      /**
       * <code>int32 bar = 1;</code>
       * @param value The bar to set.
       * @return This builder for chaining.
       */
      public Builder setBar(int value) {

        bar_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>int32 bar = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBar() {
        bitField0_ = (bitField0_ & ~0x00000001);
        bar_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:org.apache.spark.sql.protobuf.protos.Foo)
    }

    // @@protoc_insertion_point(class_scope:org.apache.spark.sql.protobuf.protos.Foo)
    private static final org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo();
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Foo>
        PARSER = new com.google.protobuf.AbstractParser<Foo>() {
      @java.lang.Override
      public Foo parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<Foo> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Foo> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Foo getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MissMatchTypeInRootOrBuilder extends
      // @@protoc_insertion_point(interface_extends:org.apache.spark.sql.protobuf.protos.MissMatchTypeInRoot)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>int64 foo = 1;</code>
     * @return The foo.
     */
    long getFoo();
  }
  /**
   * <pre>
   * Field Type missMatch in root Message
   * </pre>
   *
   * Protobuf type {@code org.apache.spark.sql.protobuf.protos.MissMatchTypeInRoot}
   */
  public static final class MissMatchTypeInRoot extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:org.apache.spark.sql.protobuf.protos.MissMatchTypeInRoot)
      MissMatchTypeInRootOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MissMatchTypeInRoot.newBuilder() to construct.
    private MissMatchTypeInRoot(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MissMatchTypeInRoot() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MissMatchTypeInRoot();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInRoot_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInRoot_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot.Builder.class);
    }

    public static final int FOO_FIELD_NUMBER = 1;
    private long foo_ = 0L;
    /**
     * <code>int64 foo = 1;</code>
     * @return The foo.
     */
    @java.lang.Override
    public long getFoo() {
      return foo_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (foo_ != 0L) {
        output.writeInt64(1, foo_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (foo_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, foo_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot other = (org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot) obj;

      if (getFoo()
          != other.getFoo()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + FOO_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getFoo());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Field Type missMatch in root Message
     * </pre>
     *
     * Protobuf type {@code org.apache.spark.sql.protobuf.protos.MissMatchTypeInRoot}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:org.apache.spark.sql.protobuf.protos.MissMatchTypeInRoot)
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRootOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInRoot_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInRoot_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot.Builder.class);
      }

      // Construct using org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        foo_ = 0L;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInRoot_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot getDefaultInstanceForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot build() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot buildPartial() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot result = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.foo_ = foo_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot) {
          return mergeFrom((org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot other) {
        if (other == org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot.getDefaultInstance()) return this;
        if (other.getFoo() != 0L) {
          setFoo(other.getFoo());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                foo_ = input.readInt64();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private long foo_ ;
      /**
       * <code>int64 foo = 1;</code>
       * @return The foo.
       */
      @java.lang.Override
      public long getFoo() {
        return foo_;
      }
      /**
       * <code>int64 foo = 1;</code>
       * @param value The foo to set.
       * @return This builder for chaining.
       */
      public Builder setFoo(long value) {

        foo_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>int64 foo = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFoo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        foo_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:org.apache.spark.sql.protobuf.protos.MissMatchTypeInRoot)
    }

    // @@protoc_insertion_point(class_scope:org.apache.spark.sql.protobuf.protos.MissMatchTypeInRoot)
    private static final org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot();
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<MissMatchTypeInRoot>
        PARSER = new com.google.protobuf.AbstractParser<MissMatchTypeInRoot>() {
      @java.lang.Override
      public MissMatchTypeInRoot parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<MissMatchTypeInRoot> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<MissMatchTypeInRoot> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInRoot getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FieldMissingInProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:org.apache.spark.sql.protobuf.protos.FieldMissingInProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
     * @return Whether the foo field is set.
     */
    boolean hasFoo();
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
     * @return The foo.
     */
    org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField getFoo();
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
     */
    org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingFieldOrBuilder getFooOrBuilder();
  }
  /**
   * <pre>
   * Field bar missing from protobuf and Available in SQL
   * </pre>
   *
   * Protobuf type {@code org.apache.spark.sql.protobuf.protos.FieldMissingInProto}
   */
  public static final class FieldMissingInProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:org.apache.spark.sql.protobuf.protos.FieldMissingInProto)
      FieldMissingInProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FieldMissingInProto.newBuilder() to construct.
    private FieldMissingInProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FieldMissingInProto() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FieldMissingInProto();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_FieldMissingInProto_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_FieldMissingInProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto.Builder.class);
    }

    public static final int FOO_FIELD_NUMBER = 1;
    private org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField foo_;
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
     * @return Whether the foo field is set.
     */
    @java.lang.Override
    public boolean hasFoo() {
      return foo_ != null;
    }
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
     * @return The foo.
     */
    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField getFoo() {
      return foo_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.getDefaultInstance() : foo_;
    }
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
     */
    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingFieldOrBuilder getFooOrBuilder() {
      return foo_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.getDefaultInstance() : foo_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (foo_ != null) {
        output.writeMessage(1, getFoo());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (foo_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getFoo());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto other = (org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto) obj;

      if (hasFoo() != other.hasFoo()) return false;
      if (hasFoo()) {
        if (!getFoo()
            .equals(other.getFoo())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFoo()) {
        hash = (37 * hash) + FOO_FIELD_NUMBER;
        hash = (53 * hash) + getFoo().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Field bar missing from protobuf and Available in SQL
     * </pre>
     *
     * Protobuf type {@code org.apache.spark.sql.protobuf.protos.FieldMissingInProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:org.apache.spark.sql.protobuf.protos.FieldMissingInProto)
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_FieldMissingInProto_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_FieldMissingInProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto.Builder.class);
      }

      // Construct using org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        foo_ = null;
        if (fooBuilder_ != null) {
          fooBuilder_.dispose();
          fooBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_FieldMissingInProto_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto getDefaultInstanceForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto build() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto buildPartial() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto result = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.foo_ = fooBuilder_ == null
              ? foo_
              : fooBuilder_.build();
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto) {
          return mergeFrom((org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto other) {
        if (other == org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto.getDefaultInstance()) return this;
        if (other.hasFoo()) {
          mergeFoo(other.getFoo());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getFooFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField foo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingFieldOrBuilder> fooBuilder_;
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
       * @return Whether the foo field is set.
       */
      public boolean hasFoo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
       * @return The foo.
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField getFoo() {
        if (fooBuilder_ == null) {
          return foo_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.getDefaultInstance() : foo_;
        } else {
          return fooBuilder_.getMessage();
        }
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
       */
      public Builder setFoo(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField value) {
        if (fooBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          foo_ = value;
        } else {
          fooBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
       */
      public Builder setFoo(
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.Builder builderForValue) {
        if (fooBuilder_ == null) {
          foo_ = builderForValue.build();
        } else {
          fooBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
       */
      public Builder mergeFoo(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField value) {
        if (fooBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            foo_ != null &&
            foo_ != org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.getDefaultInstance()) {
            getFooBuilder().mergeFrom(value);
          } else {
            foo_ = value;
          }
        } else {
          fooBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
       */
      public Builder clearFoo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        foo_ = null;
        if (fooBuilder_ != null) {
          fooBuilder_.dispose();
          fooBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.Builder getFooBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getFooFieldBuilder().getBuilder();
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingFieldOrBuilder getFooOrBuilder() {
        if (fooBuilder_ != null) {
          return fooBuilder_.getMessageOrBuilder();
        } else {
          return foo_ == null ?
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.getDefaultInstance() : foo_;
        }
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.MissingField foo = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingFieldOrBuilder> 
          getFooFieldBuilder() {
        if (fooBuilder_ == null) {
          fooBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingFieldOrBuilder>(
                  getFoo(),
                  getParentForChildren(),
                  isClean());
          foo_ = null;
        }
        return fooBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:org.apache.spark.sql.protobuf.protos.FieldMissingInProto)
    }

    // @@protoc_insertion_point(class_scope:org.apache.spark.sql.protobuf.protos.FieldMissingInProto)
    private static final org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto();
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<FieldMissingInProto>
        PARSER = new com.google.protobuf.AbstractParser<FieldMissingInProto>() {
      @java.lang.Override
      public FieldMissingInProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<FieldMissingInProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<FieldMissingInProto> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.FieldMissingInProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MissingFieldOrBuilder extends
      // @@protoc_insertion_point(interface_extends:org.apache.spark.sql.protobuf.protos.MissingField)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>int64 barFoo = 1;</code>
     * @return The barFoo.
     */
    long getBarFoo();
  }
  /**
   * Protobuf type {@code org.apache.spark.sql.protobuf.protos.MissingField}
   */
  public static final class MissingField extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:org.apache.spark.sql.protobuf.protos.MissingField)
      MissingFieldOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MissingField.newBuilder() to construct.
    private MissingField(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MissingField() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MissingField();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissingField_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissingField_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.Builder.class);
    }

    public static final int BARFOO_FIELD_NUMBER = 1;
    private long barFoo_ = 0L;
    /**
     * <code>int64 barFoo = 1;</code>
     * @return The barFoo.
     */
    @java.lang.Override
    public long getBarFoo() {
      return barFoo_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (barFoo_ != 0L) {
        output.writeInt64(1, barFoo_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (barFoo_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, barFoo_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField other = (org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField) obj;

      if (getBarFoo()
          != other.getBarFoo()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + BARFOO_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getBarFoo());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code org.apache.spark.sql.protobuf.protos.MissingField}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:org.apache.spark.sql.protobuf.protos.MissingField)
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingFieldOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissingField_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissingField_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.Builder.class);
      }

      // Construct using org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        barFoo_ = 0L;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissingField_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField getDefaultInstanceForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField build() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField buildPartial() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField result = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.barFoo_ = barFoo_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField) {
          return mergeFrom((org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField other) {
        if (other == org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField.getDefaultInstance()) return this;
        if (other.getBarFoo() != 0L) {
          setBarFoo(other.getBarFoo());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                barFoo_ = input.readInt64();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private long barFoo_ ;
      /**
       * <code>int64 barFoo = 1;</code>
       * @return The barFoo.
       */
      @java.lang.Override
      public long getBarFoo() {
        return barFoo_;
      }
      /**
       * <code>int64 barFoo = 1;</code>
       * @param value The barFoo to set.
       * @return This builder for chaining.
       */
      public Builder setBarFoo(long value) {

        barFoo_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>int64 barFoo = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBarFoo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        barFoo_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:org.apache.spark.sql.protobuf.protos.MissingField)
    }

    // @@protoc_insertion_point(class_scope:org.apache.spark.sql.protobuf.protos.MissingField)
    private static final org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField();
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<MissingField>
        PARSER = new com.google.protobuf.AbstractParser<MissingField>() {
      @java.lang.Override
      public MissingField parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<MissingField> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<MissingField> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissingField getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MissMatchTypeInDeepNestedOrBuilder extends
      // @@protoc_insertion_point(interface_extends:org.apache.spark.sql.protobuf.protos.MissMatchTypeInDeepNested)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
     * @return Whether the top field is set.
     */
    boolean hasTop();
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
     * @return The top.
     */
    org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested getTop();
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
     */
    org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNestedOrBuilder getTopOrBuilder();
  }
  /**
   * <pre>
   * Deep-nested field bar type missMatch Message
   * </pre>
   *
   * Protobuf type {@code org.apache.spark.sql.protobuf.protos.MissMatchTypeInDeepNested}
   */
  public static final class MissMatchTypeInDeepNested extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:org.apache.spark.sql.protobuf.protos.MissMatchTypeInDeepNested)
      MissMatchTypeInDeepNestedOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MissMatchTypeInDeepNested.newBuilder() to construct.
    private MissMatchTypeInDeepNested(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MissMatchTypeInDeepNested() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MissMatchTypeInDeepNested();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInDeepNested_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInDeepNested_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested.Builder.class);
    }

    public static final int TOP_FIELD_NUMBER = 1;
    private org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested top_;
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
     * @return Whether the top field is set.
     */
    @java.lang.Override
    public boolean hasTop() {
      return top_ != null;
    }
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
     * @return The top.
     */
    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested getTop() {
      return top_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.getDefaultInstance() : top_;
    }
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
     */
    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNestedOrBuilder getTopOrBuilder() {
      return top_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.getDefaultInstance() : top_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (top_ != null) {
        output.writeMessage(1, getTop());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (top_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTop());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested other = (org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested) obj;

      if (hasTop() != other.hasTop()) return false;
      if (hasTop()) {
        if (!getTop()
            .equals(other.getTop())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTop()) {
        hash = (37 * hash) + TOP_FIELD_NUMBER;
        hash = (53 * hash) + getTop().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Deep-nested field bar type missMatch Message
     * </pre>
     *
     * Protobuf type {@code org.apache.spark.sql.protobuf.protos.MissMatchTypeInDeepNested}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:org.apache.spark.sql.protobuf.protos.MissMatchTypeInDeepNested)
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNestedOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInDeepNested_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInDeepNested_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested.Builder.class);
      }

      // Construct using org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        top_ = null;
        if (topBuilder_ != null) {
          topBuilder_.dispose();
          topBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInDeepNested_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested getDefaultInstanceForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested build() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested buildPartial() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested result = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.top_ = topBuilder_ == null
              ? top_
              : topBuilder_.build();
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested) {
          return mergeFrom((org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested other) {
        if (other == org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested.getDefaultInstance()) return this;
        if (other.hasTop()) {
          mergeTop(other.getTop());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getTopFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested top_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNestedOrBuilder> topBuilder_;
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
       * @return Whether the top field is set.
       */
      public boolean hasTop() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
       * @return The top.
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested getTop() {
        if (topBuilder_ == null) {
          return top_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.getDefaultInstance() : top_;
        } else {
          return topBuilder_.getMessage();
        }
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
       */
      public Builder setTop(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested value) {
        if (topBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          top_ = value;
        } else {
          topBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
       */
      public Builder setTop(
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.Builder builderForValue) {
        if (topBuilder_ == null) {
          top_ = builderForValue.build();
        } else {
          topBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
       */
      public Builder mergeTop(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested value) {
        if (topBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            top_ != null &&
            top_ != org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.getDefaultInstance()) {
            getTopBuilder().mergeFrom(value);
          } else {
            top_ = value;
          }
        } else {
          topBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
       */
      public Builder clearTop() {
        bitField0_ = (bitField0_ & ~0x00000001);
        top_ = null;
        if (topBuilder_ != null) {
          topBuilder_.dispose();
          topBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.Builder getTopBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTopFieldBuilder().getBuilder();
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNestedOrBuilder getTopOrBuilder() {
        if (topBuilder_ != null) {
          return topBuilder_.getMessageOrBuilder();
        } else {
          return top_ == null ?
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.getDefaultInstance() : top_;
        }
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMissNested top = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNestedOrBuilder> 
          getTopFieldBuilder() {
        if (topBuilder_ == null) {
          topBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNestedOrBuilder>(
                  getTop(),
                  getParentForChildren(),
                  isClean());
          top_ = null;
        }
        return topBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:org.apache.spark.sql.protobuf.protos.MissMatchTypeInDeepNested)
    }

    // @@protoc_insertion_point(class_scope:org.apache.spark.sql.protobuf.protos.MissMatchTypeInDeepNested)
    private static final org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested();
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<MissMatchTypeInDeepNested>
        PARSER = new com.google.protobuf.AbstractParser<MissMatchTypeInDeepNested>() {
      @java.lang.Override
      public MissMatchTypeInDeepNested parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<MissMatchTypeInDeepNested> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<MissMatchTypeInDeepNested> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.MissMatchTypeInDeepNested getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface TypeMissNestedOrBuilder extends
      // @@protoc_insertion_point(interface_extends:org.apache.spark.sql.protobuf.protos.TypeMissNested)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
     * @return Whether the foo field is set.
     */
    boolean hasFoo();
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
     * @return The foo.
     */
    org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss getFoo();
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
     */
    org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissOrBuilder getFooOrBuilder();
  }
  /**
   * Protobuf type {@code org.apache.spark.sql.protobuf.protos.TypeMissNested}
   */
  public static final class TypeMissNested extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:org.apache.spark.sql.protobuf.protos.TypeMissNested)
      TypeMissNestedOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TypeMissNested.newBuilder() to construct.
    private TypeMissNested(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TypeMissNested() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new TypeMissNested();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_TypeMissNested_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_TypeMissNested_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.Builder.class);
    }

    public static final int FOO_FIELD_NUMBER = 1;
    private org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss foo_;
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
     * @return Whether the foo field is set.
     */
    @java.lang.Override
    public boolean hasFoo() {
      return foo_ != null;
    }
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
     * @return The foo.
     */
    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss getFoo() {
      return foo_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.getDefaultInstance() : foo_;
    }
    /**
     * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
     */
    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissOrBuilder getFooOrBuilder() {
      return foo_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.getDefaultInstance() : foo_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (foo_ != null) {
        output.writeMessage(1, getFoo());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (foo_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getFoo());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested other = (org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested) obj;

      if (hasFoo() != other.hasFoo()) return false;
      if (hasFoo()) {
        if (!getFoo()
            .equals(other.getFoo())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFoo()) {
        hash = (37 * hash) + FOO_FIELD_NUMBER;
        hash = (53 * hash) + getFoo().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code org.apache.spark.sql.protobuf.protos.TypeMissNested}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:org.apache.spark.sql.protobuf.protos.TypeMissNested)
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNestedOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_TypeMissNested_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_TypeMissNested_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.Builder.class);
      }

      // Construct using org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        foo_ = null;
        if (fooBuilder_ != null) {
          fooBuilder_.dispose();
          fooBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_TypeMissNested_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested getDefaultInstanceForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested build() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested buildPartial() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested result = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.foo_ = fooBuilder_ == null
              ? foo_
              : fooBuilder_.build();
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested) {
          return mergeFrom((org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested other) {
        if (other == org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested.getDefaultInstance()) return this;
        if (other.hasFoo()) {
          mergeFoo(other.getFoo());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getFooFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss foo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissOrBuilder> fooBuilder_;
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
       * @return Whether the foo field is set.
       */
      public boolean hasFoo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
       * @return The foo.
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss getFoo() {
        if (fooBuilder_ == null) {
          return foo_ == null ? org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.getDefaultInstance() : foo_;
        } else {
          return fooBuilder_.getMessage();
        }
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
       */
      public Builder setFoo(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss value) {
        if (fooBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          foo_ = value;
        } else {
          fooBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
       */
      public Builder setFoo(
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.Builder builderForValue) {
        if (fooBuilder_ == null) {
          foo_ = builderForValue.build();
        } else {
          fooBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
       */
      public Builder mergeFoo(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss value) {
        if (fooBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            foo_ != null &&
            foo_ != org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.getDefaultInstance()) {
            getFooBuilder().mergeFrom(value);
          } else {
            foo_ = value;
          }
        } else {
          fooBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
       */
      public Builder clearFoo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        foo_ = null;
        if (fooBuilder_ != null) {
          fooBuilder_.dispose();
          fooBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.Builder getFooBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getFooFieldBuilder().getBuilder();
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
       */
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissOrBuilder getFooOrBuilder() {
        if (fooBuilder_ != null) {
          return fooBuilder_.getMessageOrBuilder();
        } else {
          return foo_ == null ?
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.getDefaultInstance() : foo_;
        }
      }
      /**
       * <code>.org.apache.spark.sql.protobuf.protos.TypeMiss foo = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissOrBuilder> 
          getFooFieldBuilder() {
        if (fooBuilder_ == null) {
          fooBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.Builder, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissOrBuilder>(
                  getFoo(),
                  getParentForChildren(),
                  isClean());
          foo_ = null;
        }
        return fooBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:org.apache.spark.sql.protobuf.protos.TypeMissNested)
    }

    // @@protoc_insertion_point(class_scope:org.apache.spark.sql.protobuf.protos.TypeMissNested)
    private static final org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested();
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<TypeMissNested>
        PARSER = new com.google.protobuf.AbstractParser<TypeMissNested>() {
      @java.lang.Override
      public TypeMissNested parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<TypeMissNested> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<TypeMissNested> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissNested getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface TypeMissOrBuilder extends
      // @@protoc_insertion_point(interface_extends:org.apache.spark.sql.protobuf.protos.TypeMiss)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>int64 bar = 1;</code>
     * @return The bar.
     */
    long getBar();
  }
  /**
   * Protobuf type {@code org.apache.spark.sql.protobuf.protos.TypeMiss}
   */
  public static final class TypeMiss extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:org.apache.spark.sql.protobuf.protos.TypeMiss)
      TypeMissOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TypeMiss.newBuilder() to construct.
    private TypeMiss(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TypeMiss() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new TypeMiss();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_TypeMiss_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_TypeMiss_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.Builder.class);
    }

    public static final int BAR_FIELD_NUMBER = 1;
    private long bar_ = 0L;
    /**
     * <code>int64 bar = 1;</code>
     * @return The bar.
     */
    @java.lang.Override
    public long getBar() {
      return bar_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (bar_ != 0L) {
        output.writeInt64(1, bar_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (bar_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, bar_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss other = (org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss) obj;

      if (getBar()
          != other.getBar()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + BAR_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getBar());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code org.apache.spark.sql.protobuf.protos.TypeMiss}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:org.apache.spark.sql.protobuf.protos.TypeMiss)
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMissOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_TypeMiss_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_TypeMiss_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.Builder.class);
      }

      // Construct using org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        bar_ = 0L;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_TypeMiss_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss getDefaultInstanceForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss build() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss buildPartial() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss result = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.bar_ = bar_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss) {
          return mergeFrom((org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss other) {
        if (other == org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss.getDefaultInstance()) return this;
        if (other.getBar() != 0L) {
          setBar(other.getBar());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                bar_ = input.readInt64();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private long bar_ ;
      /**
       * <code>int64 bar = 1;</code>
       * @return The bar.
       */
      @java.lang.Override
      public long getBar() {
        return bar_;
      }
      /**
       * <code>int64 bar = 1;</code>
       * @param value The bar to set.
       * @return This builder for chaining.
       */
      public Builder setBar(long value) {

        bar_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>int64 bar = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBar() {
        bitField0_ = (bitField0_ & ~0x00000001);
        bar_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:org.apache.spark.sql.protobuf.protos.TypeMiss)
    }

    // @@protoc_insertion_point(class_scope:org.apache.spark.sql.protobuf.protos.TypeMiss)
    private static final org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss();
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<TypeMiss>
        PARSER = new com.google.protobuf.AbstractParser<TypeMiss>() {
      @java.lang.Override
      public TypeMiss parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<TypeMiss> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<TypeMiss> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.TypeMiss getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BazOrBuilder extends
      // @@protoc_insertion_point(interface_extends:org.apache.spark.sql.protobuf.protos.Baz)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>int32 bar = 1;</code>
     * @return The bar.
     */
    int getBar();

    /**
     * <code>int32 baz = 2;</code>
     * @return The baz.
     */
    int getBaz();
  }
  /**
   * Protobuf type {@code org.apache.spark.sql.protobuf.protos.Baz}
   */
  public static final class Baz extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:org.apache.spark.sql.protobuf.protos.Baz)
      BazOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Baz.newBuilder() to construct.
    private Baz(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Baz() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Baz();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_Baz_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_Baz_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz.Builder.class);
    }

    public static final int BAR_FIELD_NUMBER = 1;
    private int bar_ = 0;
    /**
     * <code>int32 bar = 1;</code>
     * @return The bar.
     */
    @java.lang.Override
    public int getBar() {
      return bar_;
    }

    public static final int BAZ_FIELD_NUMBER = 2;
    private int baz_ = 0;
    /**
     * <code>int32 baz = 2;</code>
     * @return The baz.
     */
    @java.lang.Override
    public int getBaz() {
      return baz_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (bar_ != 0) {
        output.writeInt32(1, bar_);
      }
      if (baz_ != 0) {
        output.writeInt32(2, baz_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (bar_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, bar_);
      }
      if (baz_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, baz_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz)) {
        return super.equals(obj);
      }
      org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz other = (org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz) obj;

      if (getBar()
          != other.getBar()) return false;
      if (getBaz()
          != other.getBaz()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + BAR_FIELD_NUMBER;
      hash = (53 * hash) + getBar();
      hash = (37 * hash) + BAZ_FIELD_NUMBER;
      hash = (53 * hash) + getBaz();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code org.apache.spark.sql.protobuf.protos.Baz}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:org.apache.spark.sql.protobuf.protos.Baz)
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.BazOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_Baz_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_Baz_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz.class, org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz.Builder.class);
      }

      // Construct using org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        bar_ = 0;
        baz_ = 0;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.internal_static_org_apache_spark_sql_protobuf_protos_Baz_descriptor;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz getDefaultInstanceForType() {
        return org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz build() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz buildPartial() {
        org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz result = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.bar_ = bar_;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.baz_ = baz_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz) {
          return mergeFrom((org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz other) {
        if (other == org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz.getDefaultInstance()) return this;
        if (other.getBar() != 0) {
          setBar(other.getBar());
        }
        if (other.getBaz() != 0) {
          setBaz(other.getBaz());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                bar_ = input.readInt32();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              case 16: {
                baz_ = input.readInt32();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int bar_ ;
      /**
       * <code>int32 bar = 1;</code>
       * @return The bar.
       */
      @java.lang.Override
      public int getBar() {
        return bar_;
      }
      /**
       * <code>int32 bar = 1;</code>
       * @param value The bar to set.
       * @return This builder for chaining.
       */
      public Builder setBar(int value) {

        bar_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>int32 bar = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBar() {
        bitField0_ = (bitField0_ & ~0x00000001);
        bar_ = 0;
        onChanged();
        return this;
      }

      private int baz_ ;
      /**
       * <code>int32 baz = 2;</code>
       * @return The baz.
       */
      @java.lang.Override
      public int getBaz() {
        return baz_;
      }
      /**
       * <code>int32 baz = 2;</code>
       * @param value The baz to set.
       * @return This builder for chaining.
       */
      public Builder setBaz(int value) {

        baz_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>int32 baz = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearBaz() {
        bitField0_ = (bitField0_ & ~0x00000002);
        baz_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:org.apache.spark.sql.protobuf.protos.Baz)
    }

    // @@protoc_insertion_point(class_scope:org.apache.spark.sql.protobuf.protos.Baz)
    private static final org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz();
    }

    public static org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Baz>
        PARSER = new com.google.protobuf.AbstractParser<Baz>() {
      @java.lang.Override
      public Baz parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<Baz> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Baz> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.spark.sql.protobuf.protos.SerdeSuiteProtos.Baz getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_spark_sql_protobuf_protos_SerdeBasicMessage_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_spark_sql_protobuf_protos_SerdeBasicMessage_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_spark_sql_protobuf_protos_Foo_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_spark_sql_protobuf_protos_Foo_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInRoot_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInRoot_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_spark_sql_protobuf_protos_FieldMissingInProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_spark_sql_protobuf_protos_FieldMissingInProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_spark_sql_protobuf_protos_MissingField_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_spark_sql_protobuf_protos_MissingField_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInDeepNested_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInDeepNested_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_spark_sql_protobuf_protos_TypeMissNested_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_spark_sql_protobuf_protos_TypeMissNested_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_spark_sql_protobuf_protos_TypeMiss_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_spark_sql_protobuf_protos_TypeMiss_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_spark_sql_protobuf_protos_Baz_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_spark_sql_protobuf_protos_Baz_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\021serde_suite.proto\022$org.apache.spark.sq" +
      "l.protobuf.protos\"K\n\021SerdeBasicMessage\0226" +
      "\n\003foo\030\001 \001(\0132).org.apache.spark.sql.proto" +
      "buf.protos.Foo\"\022\n\003Foo\022\013\n\003bar\030\001 \001(\005\"\"\n\023Mi" +
      "ssMatchTypeInRoot\022\013\n\003foo\030\001 \001(\003\"V\n\023FieldM" +
      "issingInProto\022?\n\003foo\030\001 \001(\01322.org.apache." +
      "spark.sql.protobuf.protos.MissingField\"\036" +
      "\n\014MissingField\022\016\n\006barFoo\030\001 \001(\003\"^\n\031MissMa" +
      "tchTypeInDeepNested\022A\n\003top\030\001 \001(\01324.org.a" +
      "pache.spark.sql.protobuf.protos.TypeMiss" +
      "Nested\"M\n\016TypeMissNested\022;\n\003foo\030\001 \001(\0132.." +
      "org.apache.spark.sql.protobuf.protos.Typ" +
      "eMiss\"\027\n\010TypeMiss\022\013\n\003bar\030\001 \001(\003\"\037\n\003Baz\022\013\n" +
      "\003bar\030\001 \001(\005\022\013\n\003baz\030\002 \001(\005B\022B\020SerdeSuitePro" +
      "tosb\006proto3"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        });
    internal_static_org_apache_spark_sql_protobuf_protos_SerdeBasicMessage_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_org_apache_spark_sql_protobuf_protos_SerdeBasicMessage_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_spark_sql_protobuf_protos_SerdeBasicMessage_descriptor,
        new java.lang.String[] { "Foo", });
    internal_static_org_apache_spark_sql_protobuf_protos_Foo_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_org_apache_spark_sql_protobuf_protos_Foo_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_spark_sql_protobuf_protos_Foo_descriptor,
        new java.lang.String[] { "Bar", });
    internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInRoot_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInRoot_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInRoot_descriptor,
        new java.lang.String[] { "Foo", });
    internal_static_org_apache_spark_sql_protobuf_protos_FieldMissingInProto_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_org_apache_spark_sql_protobuf_protos_FieldMissingInProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_spark_sql_protobuf_protos_FieldMissingInProto_descriptor,
        new java.lang.String[] { "Foo", });
    internal_static_org_apache_spark_sql_protobuf_protos_MissingField_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_org_apache_spark_sql_protobuf_protos_MissingField_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_spark_sql_protobuf_protos_MissingField_descriptor,
        new java.lang.String[] { "BarFoo", });
    internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInDeepNested_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInDeepNested_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_spark_sql_protobuf_protos_MissMatchTypeInDeepNested_descriptor,
        new java.lang.String[] { "Top", });
    internal_static_org_apache_spark_sql_protobuf_protos_TypeMissNested_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_org_apache_spark_sql_protobuf_protos_TypeMissNested_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_spark_sql_protobuf_protos_TypeMissNested_descriptor,
        new java.lang.String[] { "Foo", });
    internal_static_org_apache_spark_sql_protobuf_protos_TypeMiss_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_org_apache_spark_sql_protobuf_protos_TypeMiss_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_spark_sql_protobuf_protos_TypeMiss_descriptor,
        new java.lang.String[] { "Bar", });
    internal_static_org_apache_spark_sql_protobuf_protos_Baz_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_org_apache_spark_sql_protobuf_protos_Baz_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_spark_sql_protobuf_protos_Baz_descriptor,
        new java.lang.String[] { "Bar", "Baz", });
  }

  // @@protoc_insertion_point(outer_class_scope)
}
