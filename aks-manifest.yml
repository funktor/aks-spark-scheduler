apiVersion: sparkoperator.k8s.io/v1beta2
kind: ScheduledSparkApplication
metadata:
  name: spark-task
  namespace: default
spec:
  # Run the job every day at 3 AM
  schedule: "0 3 * * *" 
  concurrencyPolicy: Allow
  template:
    type: Python
    pythonVersion: "3"
    mode: cluster
    image: amondal.azurecr.io/aks-scheduler:latest
    imagePullPolicy: Always
    mainClass: org.apache.spark.examples.SparkPi
    mainApplicationFile: 'local:///app/aks_executor.py'
    imagePullSecrets:
      - my-secret
    deps:
      packages:
        - org.apache.hadoop:hadoop-azure:3.3.5
    restartPolicy:
      type: OnFailure
      onFailureRetries: 3
      onFailureRetryInterval: 10
      onSubmissionFailureRetries: 5
      onSubmissionFailureRetryInterval: 20
    sparkVersion: "3.4.2"
    dynamicAllocation:
      enabled: true
      initialExecutors: 1
      minExecutors: 1
      maxExecutors: 160
    driver:
      serviceAccount: spark
      javaOptions: "-Divy.cache.dir=/tmp -Divy.home=/tmp"
      envSecretKeyRefs:
        APP_ID:
          name: app
          key: app_id
        TENANT_ID:
          name: app
          key: tenant_id
        APP_SECRET:
          name: app
          key: app_secret
        BLOB_STORAGE_URL:
          name: app
          key: blob_storage_url
        BLOB_STORAGE_INP_CONTAINER:
          name: app
          key: blob_storage_inp
        BLOB_STORAGE_OUT_CONTAINER:
          name: app
          key: blob_storage_out
    executor:
      envSecretKeyRefs:
        APP_ID:
          name: app
          key: app_id
        TENANT_ID:
          name: app
          key: tenant_id
        APP_SECRET:
          name: app
          key: app_secret
        BLOB_STORAGE_URL:
          name: app
          key: blob_storage_url
        BLOB_STORAGE_INP_CONTAINER:
          name: app
          key: blob_storage_inp
        BLOB_STORAGE_OUT_CONTAINER:
          name: app
          key: blob_storage_out